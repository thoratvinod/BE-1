{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('07_Train_UWu5bXk.csv')\n",
    "Test = pd.read_csv('07_Test_u94Q5KV.csv')\n",
    "X_train, y_train = Train.iloc[:, :-1].values, Train.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility    Item_Type  \\\n",
      "0           FDW58       20.750          Low Fat         0.007565  Snack Foods   \n",
      "1           FDW14        8.300              reg         0.038428        Dairy   \n",
      "2           NCN55       14.600          Low Fat         0.099575       Others   \n",
      "3           FDQ58        7.315          Low Fat         0.015388  Snack Foods   \n",
      "4           FDY38          NaN          Regular         0.118599        Dairy   \n",
      "\n",
      "   Item_MRP Outlet_Identifier  Outlet_Establishment_Year Outlet_Size  \\\n",
      "0  107.8622            OUT049                       1999      Medium   \n",
      "1   87.3198            OUT017                       2007         NaN   \n",
      "2  241.7538            OUT010                       1998         NaN   \n",
      "3  155.0340            OUT017                       2007         NaN   \n",
      "4  234.2300            OUT027                       1985      Medium   \n",
      "\n",
      "  Outlet_Location_Type        Outlet_Type  \n",
      "0               Tier 1  Supermarket Type1  \n",
      "1               Tier 2  Supermarket Type1  \n",
      "2               Tier 3      Grocery Store  \n",
      "3               Tier 2  Supermarket Type1  \n",
      "4               Tier 3  Supermarket Type3  \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20.75, 8.3, 14.6, 7.315, nan], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = Test[:5]\n",
    "print(temp)\n",
    "print('-'*100)\n",
    "temp = temp.values\n",
    "temp[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataset):\n",
    "    X_dataset = dataset.values\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    impute = Imputer(missing_values='NaN',strategy='mean')\n",
    "    column1 = X_dataset[:,1].reshape(-1,1);\n",
    "    X_dataset[:,1] = impute.fit_transform(column1).reshape(1,-1)\n",
    "    \n",
    "    X_dataset = pd.DataFrame(X_dataset)\n",
    "    X_dataset.iloc[:,2].map({'reg':'Regular','LF':'Low Fat','low fat':'Low Fat','Low Fat':'Low Fat','Regular':'Regular'})\n",
    "    X_dataset = X_dataset.values\n",
    "    \n",
    "    import sklearn.preprocessing\n",
    "    encoder1 = sklearn.preprocessing.LabelEncoder()\n",
    "    X_dataset[:,2] = encoder1.fit_transform(X_dataset[:,2])\n",
    "    encoder2 = sklearn.preprocessing.LabelEncoder()\n",
    "    X_dataset[:,9] = encoder2.fit_transform(X_dataset[:,9])\n",
    "    encoder3 = sklearn.preprocessing.LabelEncoder()\n",
    "    X_dataset[:,10] = encoder1.fit_transform(X_dataset[:,10])\n",
    "    \n",
    "    X_dataset = X_dataset[:,[1,2,3,5,7,9,10]]\n",
    "    ohe_1 = sklearn.preprocessing.OneHotEncoder(categorical_features=[5,6])\n",
    "    X_dataset = ohe_1.fit_transform(X_dataset).toarray()\n",
    "    return X_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created result.csv file!!!\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocessing(Train)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regression = LinearRegression()\n",
    "regression.fit(X_train,y_train)\n",
    "X_test = preprocessing(Test)\n",
    "y_pred = regression.predict(X_test)\n",
    "\n",
    "X_df = pd.DataFrame(X_test)\n",
    "y_df = pd.DataFrame(y_pred)\n",
    "Headers = pd.DataFrame(Test.iloc[:,[0,6]])\n",
    "\n",
    "Result = pd.concat([Headers,X_df,y_df], axis=1, ignore_index=True)\n",
    "Result = Result.rename(columns={0:'Item Identifier',1:'Outlet Identifier',14: 'predicted Outlet Sales'})\n",
    "Result.to_csv(\"result.csv\",index=False)\n",
    "print(\"Successfully created result.csv file!!!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
